{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-remains",
   "metadata": {},
   "source": [
    "# Build ratios of tectonic region areas over total planet area \n",
    "This code computes the surface ratio from any point on the planet, i.e., any source location, up to a given distance on a sphere. This is used to determine how many venusquakes can be triggered in a given radius from a balloon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, MultiLineString, Point\n",
    "from shapely.ops import split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.validation import make_valid\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-sending",
   "metadata": {},
   "source": [
    "## Load tectonic regions of Venus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VENUS_DATA = os.path.join(\"./test_data_Venus/Venus_data/\")\n",
    "PATH_VENUS = os.path.join(f\"{PATH_VENUS_DATA}tectonic_settings_Venus\")\n",
    "VENUS = {\n",
    "    'corona': gpd.read_file(f\"{PATH_VENUS}/corona.shp\"),\n",
    "    'rift': gpd.read_file(f\"{PATH_VENUS}/rifts.shp\"),\n",
    "    'ridge': gpd.read_file(f\"{PATH_VENUS}/ridges.shp\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-radiation",
   "metadata": {},
   "source": [
    "## Compute surface ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "furnished-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- resampling TL boundaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [02:39<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- corona -\n",
      "- Finding region polygons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529/529 [00:04<00:00, 126.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Looping over all sensor locations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [02:19<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rift -\n",
      "- Finding region polygons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 86.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Looping over all sensor locations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 61/81 [00:12<00:04,  4.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9fbae1e1c9d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mratio_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_surface_area_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolygon2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0mloc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lon'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlon_0_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlat_0_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iradius'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'radius'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ratio_map'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mratio_map\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mratio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratio_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0;31m#plot_TL_map(polygon_map, polygon1s[itotal], polygon2, intersection, proj, lon_0_current, lat_0_current)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7969\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7970\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7971\u001b[0;31m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7972\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7973\u001b[0m                     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _list_of_dict_to_arrays(\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         )\n\u001b[1;32m    533\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_of_dict_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicts_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/seismonpy/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_array_function_like_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def spherical_cap_boundary(lat_0, lon_0, radius, R0, num_points=100):\n",
    "    \"\"\"\n",
    "    Compute a list of latitude, longitudes corresponding to the boundary of a spherical cap.\n",
    "\n",
    "    Parameters:\n",
    "    lat_0, lon_0: Center of the spherical cap in degrees.\n",
    "    radius: Radius of the spherical cap in meters.\n",
    "    R0: Radius of the sphere in meters.\n",
    "    num_points: Number of points to generate along the boundary.\n",
    "\n",
    "    Returns:\n",
    "    A list of (lat, lon) tuples representing the boundary of the spherical cap.\n",
    "    \"\"\"\n",
    "    # Convert the center coordinates to radians\n",
    "    lat_0_rad = np.radians(lat_0)\n",
    "    lon_0_rad = np.radians(lon_0)\n",
    "\n",
    "    # Compute the angular radius of the cap\n",
    "    angular_radius = radius / R0\n",
    "\n",
    "    # Generate a list of angles\n",
    "    angles = np.linspace(0, 2*np.pi, num_points)\n",
    "\n",
    "    # Compute the latitude and longitude of each point on the boundary\n",
    "    lat_rad = np.arcsin(np.sin(lat_0_rad)*np.cos(angular_radius) + np.cos(lat_0_rad)*np.sin(angular_radius)*np.cos(angles))\n",
    "    lon_rad = lon_0_rad + np.arctan2(np.sin(angles)*np.sin(angular_radius)*np.cos(lat_0_rad), np.cos(angular_radius) - np.sin(lat_0_rad)*np.sin(lat_rad))\n",
    "\n",
    "    # Convert the coordinates back to degrees\n",
    "    lat = np.degrees(lat_rad)\n",
    "    lon = np.degrees(lon_rad)\n",
    "    #lon[lon < 0] += 360.\n",
    "\n",
    "    # Combine the latitude and longitude into a list of tuples\n",
    "    boundary = list(zip(lon, lat))\n",
    "\n",
    "    return boundary\n",
    "\n",
    "def spherical_cap_boundary_v2(g, lat_0, lon_0, radius, num_points=100):\n",
    "\n",
    "    n_radius = len(l_radius)\n",
    "    lat, lon = np.repeat(lat_0, n_radius*num_points), np.repeat(lon_0, n_radius*num_points)\n",
    "    angles = np.linspace(1., 359., n_radius*num_points)\n",
    "    R = np.repeat(l_radius, num_points)\n",
    "    endlon, endlat, _ = g.fwd(lon, lat, angles, R)\n",
    "\n",
    "    return list(zip(endlon, endlat))\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "def resample_trajectory(proj, shape_init, lon_0, lon_loc, lon_traj, lat_traj, n_loc, n_radius, num_points_init, num_points):\n",
    "    \n",
    "    lon_traj_r, lat_traj_r = lon_traj.reshape(shape_init), lat_traj.reshape(shape_init)\n",
    "    lon_loc_r = lon_loc.reshape(shape_init)\n",
    "    \n",
    "    n_subshapes = []\n",
    "    #icoords = np.arange(lon_traj.size)\n",
    "    #icoords_new = np.arange(n_loc*n_radius*num_points)\n",
    "    #new_coords = np.zeros((icoords_new.size,2))\n",
    "    new_coords_lat = np.zeros((num_points,)+lon_traj_r.shape[1:])\n",
    "    new_coords_lon = np.zeros((num_points,)+lon_traj_r.shape[1:])\n",
    "    print('- resampling TL boundaries')\n",
    "    for iloc in tqdm(range(n_loc)):\n",
    "        #icoords_loc = icoords[iloc*num_points_init*n_radius:(iloc+1)*num_points_init*n_radius]\n",
    "        #icoords_loc_new = icoords_new[iloc*num_points*n_radius:(iloc+1)*num_points*n_radius]\n",
    "        #lon_0_current = lon_loc[icoords_loc[0]]\n",
    "        lon_0_current = lon_loc_r[0,iloc,0]\n",
    "        proj_sensor = proj(lon_0_current, 0.)\n",
    "        proj_sensor_ref = proj(lon_0, 0.)\n",
    "        offset = abs(proj_sensor_ref[0]-proj_sensor[0])\n",
    "        #print(f'offset: {offset} | lon_0_current: {lon_0_current}')\n",
    "\n",
    "        for iradius in range(n_radius):\n",
    "            \n",
    "            #print(f'Radius: {iradius}')\n",
    "            \n",
    "            #icoords_loc_loc = icoords_loc[iradius*num_points_init:(iradius+1)*num_points_init]\n",
    "            #icoords_loc_loc_new = icoords_loc_new[iradius*num_points:(iradius+1)*num_points]\n",
    "            #trajectory = np.c_[lon_traj[icoords_loc_loc], lat_traj[icoords_loc_loc]]\n",
    "            trajectory = np.c_[lon_traj_r[:,iloc,iradius], lat_traj_r[:,iloc,iradius]]\n",
    "            ind = -np.argmax(abs(trajectory[:,0]-offset))-1\n",
    "            trajectory = np.roll(trajectory, ind, axis=0)\n",
    "            #print(f'- {iradius}: {ind} ({np.max(abs(trajectory[:,0]-offset))})')\n",
    "            \n",
    "            # Unpack the coordinates\n",
    "            x, y = zip(*trajectory)\n",
    "            x, y = x[:-1], y[:-1]\n",
    "\n",
    "            # Compute the cumulative distance along the trajectory\n",
    "            distance = np.cumsum(np.sqrt(np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2))\n",
    "            \n",
    "            num_shapes = 1\n",
    "            isep = distance.size\n",
    "            threshold = 4e6\n",
    "            loc_maxs = []\n",
    "            #print(f'- max distance: {np.max(np.diff(distance))} (ratio: {np.max(np.diff(distance))/threshold})')\n",
    "            if np.max(np.diff(distance)) > threshold:\n",
    "                loc_maxs = np.where(np.diff(distance)>threshold)[0]\n",
    "                dist_begin_end = np.sqrt((x[0]-x[-1])**2+(y[0]-y[-1])**2)\n",
    "                #print(f'- len(loc_maxs): {len(loc_maxs)}')\n",
    "                #print(f'- dist_begin_end: {dist_begin_end} (ratio: {dist_begin_end/threshold})')\n",
    "                # Check if there is two shapes\n",
    "                # Either two large distances between neighboring points or beginning and end of trajectory not close to each other\n",
    "                if (len(loc_maxs) > 1) or ((len(loc_maxs) == 1) and (dist_begin_end > threshold)): \n",
    "                    num_shapes += 1\n",
    "                    isep = np.argmax(np.diff(distance))+1\n",
    "                \n",
    "                if loc_maxs.size > 1:\n",
    "                    ind = trajectory.size - np.max(loc_maxs) - 1\n",
    "                    trajectory = np.roll(trajectory, ind, axis=0)\n",
    "                    x, y = zip(*trajectory)\n",
    "                    x, y = x[:-1], y[:-1]\n",
    "                    distance = np.cumsum(np.sqrt(np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2))\n",
    "                    isep = np.argmax(np.diff(distance))+1\n",
    "                \n",
    "            #print(f'isep: {isep} | num_shapes: {num_shapes} | loc_maxs: {loc_maxs}')\n",
    "                \n",
    "            n_subshapes.append(num_shapes)\n",
    "                \n",
    "            #plt.figure()\n",
    "            #plt.title(f'{isep}/{len(x)} ({num_shapes})')\n",
    "            #plt.scatter(x, y, c=np.arange(len(x)), alpha=0.5)\n",
    "            for ishape in range(num_shapes):\n",
    "                \n",
    "                # Unpack the coordinates\n",
    "                if ishape == 0:\n",
    "                    x, y = zip(*trajectory[:isep,:])\n",
    "                else:\n",
    "                    x, y = zip(*trajectory[isep:,:])\n",
    "                x, y = x[:-1], y[:-1]\n",
    "\n",
    "                #plt.plot(x, y,)\n",
    "                #plt.scatter(x[0], y[0], marker='x', c='red')\n",
    "                #plt.scatter(x[-1], y[-1], marker='o', facecolor=None, edgecolor='red')\n",
    "            \n",
    "                # Compute the cumulative distance along the trajectory\n",
    "                distance = np.cumsum(np.sqrt(np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2))\n",
    "\n",
    "                # Normalize the distance values to be between 0 and 1\n",
    "                distance = distance / distance[-1]\n",
    "                \n",
    "                # Perform cubic spline interpolation\n",
    "                spline, u = interpolate.splprep([x, y], s=0, u=distance)\n",
    "                \n",
    "                #plt.figure()\n",
    "                #plt.scatter(x,y)\n",
    "                #plt.plot(x,y)\n",
    "                \n",
    "                # Compute the total length of the trajectory\n",
    "                total_length = np.hypot(x[-1]-x[0], y[-1]-y[0])\n",
    "\n",
    "                # Determine the number of points to sample\n",
    "                #num_points = int(total_length / D)\n",
    "\n",
    "                # Generate the normalized distances of the new points\n",
    "                num_points_shape = num_points//num_shapes\n",
    "                u_new = np.linspace(0, 1, num_points_shape)\n",
    "\n",
    "                # Compute the new coordinates\n",
    "                new_coords_loc = interpolate.splev(u_new, spline)\n",
    "                #print(num_points_shape*ishape, num_points_shape*(ishape+1), icoords_loc_loc_new.shape, new_coords_loc[0].shape)\n",
    "                #print(icoords_loc_loc_new[num_points_shape*ishape:num_points_shape*(ishape+1)].shape)\n",
    "                #print(new_coords.shape)\n",
    "                #print(new_coords_loc[0].shape, num_points_shape, ishape, icoords_loc_loc_new[num_points_shape*ishape:num_points_shape*(ishape+1)].min(), icoords_loc_loc_new[num_points_shape*ishape:num_points_shape*(ishape+1)].max())\n",
    "                #new_coords[icoords_loc_loc_new[num_points_shape*ishape:num_points_shape*(ishape+1)],:] = np.c_[new_coords_loc[0], new_coords_loc[1]]\n",
    "                new_coords_lon[num_points_shape*ishape:num_points_shape*(ishape+1),iloc,iradius] = new_coords_loc[0]\n",
    "                new_coords_lat[num_points_shape*ishape:num_points_shape*(ishape+1),iloc,iradius] = new_coords_loc[1]\n",
    "                \n",
    "                #plt.axvline(x[0])\n",
    "                #plt.scatter(new_coords_loc[0], new_coords_loc[1], s=10)\n",
    "        \n",
    "    return new_coords_lon, new_coords_lat, n_subshapes\n",
    "\n",
    "def spherical_cap_boundary_v3(g, proj, lon_reference, l_lat_0, l_lon_0, l_radius, num_points=100):\n",
    "\n",
    "    num_points_init = num_points*10\n",
    "    n_loc = l_lat_0.size\n",
    "    n_radius = len(l_radius)\n",
    "    #lat, lon = np.repeat(l_lat_0, n_radius*num_points_init), np.repeat(l_lon_0, n_radius*num_points_init)\n",
    "    #iloc = np.repeat(np.arange(n_loc), n_radius*num_points_init)\n",
    "    l_angles = np.linspace(0., 359.9999, num_points_init)\n",
    "    #angles = np.tile(l_angles, n_radius*n_loc)\n",
    "    #R = np.repeat(l_radius, num_points_init*n_loc)\n",
    "    \n",
    "    iloc, angles, R = np.meshgrid(np.arange(n_loc), l_angles, l_radius)\n",
    "    shape_init = iloc.shape\n",
    "    angles, R, iloc = angles.ravel(), R.ravel(), iloc.ravel()\n",
    "    lon, lat = l_lon_0[iloc], l_lat_0[iloc]\n",
    "    \n",
    "    endlon_deg, endlat_deg, _ = g.fwd(lon, lat, angles, R)\n",
    "    endlon, endlat = proj(endlon_deg, endlat_deg)\n",
    "    \n",
    "    \"\"\"\n",
    "    dists = [0.]\n",
    "    for iloc in range(1, endlon.size):\n",
    "        #_, _, dist = g.inv(endlon[iloc], endlat[iloc], endlon[iloc-1], endlat[iloc-1])\n",
    "        dist = np.sqrt((endlon[iloc]-endlon[iloc-1])**2 + (endlat[iloc]-endlat[iloc-1])**2)\n",
    "        dists.append( dist )\n",
    "    cum_dists = np.cumsum(dists)\n",
    "    \n",
    "    l_dists = np.linspace(0., cum_dists[-1], num_points)\n",
    "    delta_dist = l_dists[1]\n",
    "    endlon_new = [endlon[0]]\n",
    "    endlat_new = [endlat[0]]\n",
    "    for iloc in range(1, l_dists.size):\n",
    "        current_dist = l_dists[iloc]\n",
    "        iclosest = (np.arange(endlon.size)[cum_dists>current_dist])[0]-1\n",
    "        one_endlat = np.interp(current_dist-cum_dists[iclosest], [endlon[iclosest], endlon[iclosest+1]], endlat[iclosest], endlat[iclosest+1])\n",
    "    \"\"\"\n",
    "    coords_lon, coords_lat, n_subshapes = resample_trajectory(proj, shape_init, lon_reference, lon, endlon, endlat, n_loc, n_radius, num_points_init, num_points)\n",
    "    #print(coords)\n",
    "    \n",
    "    return coords_lon, coords_lat, n_subshapes, endlon.reshape(shape_init), endlat.reshape(shape_init)\n",
    "        \n",
    "def compute_region_venus(polygon_map, ext_points, proj, show_bar=True):\n",
    "\n",
    "    # ext_points: e.g., VENUS['rift'].exterior\n",
    "    polygon2 = Polygon()\n",
    "    for ext in tqdm(ext_points, disable=show_bar):\n",
    "        if ext is None:\n",
    "            continue\n",
    "        surface2 = list(ext.coords)\n",
    "        coords = np.array([proj(lon, lat) for lon, lat in surface2])\n",
    "        clustering = DBSCAN(eps=500000, min_samples=5).fit(coords)\n",
    "        lines = []\n",
    "        #print(f'labels: {np.unique(clustering.labels_)}')\n",
    "        for label in np.unique(clustering.labels_):\n",
    "            #print(f'- size: {coords[clustering.labels_==label].shape[0]}')\n",
    "            if coords[clustering.labels_==label].shape[0] > 1:\n",
    "                lines.append( LineString(coords[clustering.labels_==label]).buffer(200000) )\n",
    "        lines = MultiPolygon(lines)\n",
    "        #print('lines', lines.geom_type)\n",
    "        #print('polygon2', polygon2.geom_type)\n",
    "        diff_map = polygon_map.difference(make_valid(lines))\n",
    "        #print('diff_map', diff_map.geom_type)\n",
    "        if diff_map.geom_type == 'MultiPolygon':\n",
    "            ipolymax = -1\n",
    "            max_val = -1\n",
    "            for ipoly, sub_poly in enumerate(diff_map.geoms):\n",
    "                if sub_poly.area > max_val:\n",
    "                    ipolymax = ipoly\n",
    "                    max_val = sub_poly.area\n",
    "\n",
    "            for ipoly, sub_poly in enumerate(diff_map.geoms):\n",
    "                if not ipoly == ipolymax:\n",
    "                    continue \n",
    "                diff_map = polygon_map.difference(sub_poly)\n",
    "            \n",
    "            #print('diff_map2', diff_map.geom_type)\n",
    "        \n",
    "            diff_map = make_valid(diff_map)\n",
    "            #print('diff_map3', diff_map.geom_type)\n",
    "            if diff_map.geom_type == 'MultiPolygon':\n",
    "                for ipoly, sub_poly in enumerate(diff_map.geoms):\n",
    "                    #if ipoly == ipolymax:\n",
    "                    #    continue \n",
    "                    if sub_poly.geom_type == 'Polygon':\n",
    "                        #print('sub_poly', sub_poly.buffer(10))\n",
    "                        polygon2 = polygon2.union( sub_poly.buffer(10) )\n",
    "                    #exts.append(iext)\n",
    "            else:\n",
    "                #print('diff_map3 before polygon2', polygon2.geom_type)\n",
    "                #bef = polygon2.geom_type\n",
    "                #polygon2_bef = polygon2\n",
    "                polygon2 = polygon2.union( diff_map.buffer(10) )\n",
    "                #aft = polygon2.geom_type\n",
    "                #if bef == 'MultiPolygon' and aft == 'GeometryCollection':\n",
    "                #    return polygon2, polygon2_bef, diff_map\n",
    "                #print('diff_map3 after polygon2', polygon2.geom_type)\n",
    "                \n",
    "    else:\n",
    "        polygon2 = polygon2.union(lines)\n",
    "                \n",
    "    polygon2 = make_valid(polygon2)\n",
    "    return polygon2\n",
    "\n",
    "def compute_whole_map_region(lon_0, proj, dlon=10., dlat=10.): \n",
    "\n",
    "    left_lon  = -180.01+lon_0 if lon_0 > 0 else 180.01+lon_0\n",
    "    right_lon = -179.01+lon_0 if lon_0 > 0 else 179.01+lon_0\n",
    "    bottom_lat = -89.9#+lat_0 if lat_0 > 0 else 90+lat_0\n",
    "    top_lat = 89.9#+lat_0 if lat_0 < 0 else -90+lat_0\n",
    "    \n",
    "    coords_map = [proj(lon, bottom_lat) for lon in np.arange(left_lon, right_lon, dlon)]\n",
    "    coords_map += [proj(right_lon, lat) for lat in np.arange(bottom_lat, top_lat, dlat)]\n",
    "    coords_map += [proj(lon, top_lat) for lon in np.arange(right_lon, left_lon, -dlon)]\n",
    "    coords_map += [proj(left_lon, lat) for lat in np.arange(top_lat, bottom_lat, -dlat)]\n",
    "    polygon_map = Polygon(coords_map)\n",
    "    return polygon_map, coords_map\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def compute_TL_region_v2(polygon_map, coords_poly1, proj, lon_0, lon_0_current, sensor, n_subshape, subsample_db=1, buffer_line=300000, buffer_sensor=180000, n_init_max=10, threshold_neighbor_pts = 5e5):\n",
    "    \n",
    "    proj_sensor = proj(lon_0_current, 0.)\n",
    "    proj_sensor_ref = proj(lon_0, 0.)\n",
    "    offset = abs(proj_sensor_ref[0]-proj_sensor[0])\n",
    "\n",
    "    #coords_poly1 = np.roll(coords_poly1, -np.argmax(abs(coords_poly1[:,0]-offset))-1, axis=0)\n",
    "    last_area = 0\n",
    "    #plt.figure()\n",
    "    #plt.title(n_subshape)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    coords_poly1_fixed = scaler.fit_transform(coords_poly1)\n",
    "    \n",
    "    for iin, n_components in enumerate([n_subshape]):\n",
    "        \n",
    "        l_n_init = np.arange(1,n_init_max)\n",
    "        l_covariances = ['full', 'spherical']\n",
    "        NINIT, COV = np.meshgrid(l_n_init, l_covariances)\n",
    "        NINIT, COV = NINIT.ravel(), COV.ravel()\n",
    "        for n_init, cov in zip(NINIT, COV):\n",
    "        \n",
    "            #print(f'---> n_comp: {n_components} n_init: {n_init} cov: {cov}')\n",
    "        \n",
    "            clustering = GaussianMixture(n_components=n_components, n_init=n_init, covariance_type=cov).fit_predict(coords_poly1_fixed)\n",
    "            polygon1 = Polygon()\n",
    "            max_dx = 0.\n",
    "            for label in np.unique(clustering):\n",
    "                max_dx = max(max_dx, abs(np.diff(coords_poly1[clustering==label][:-1,0])).max())\n",
    "                #plt.plot(coords_poly1[clustering==label][:-1,0], coords_poly1[clustering==label][:-1,1])\n",
    "                polygon1 = polygon1.union( LineString(coords_poly1[clustering==label][:-1]).buffer(buffer_line) )\n",
    "            \n",
    "            if max_dx > threshold_neighbor_pts: # Check for potential issues with clustering, i.e., shared points between shapes\n",
    "                continue\n",
    "            \n",
    "            diff_poly = polygon_map.difference(polygon1.buffer(10)) # The buffer here is to avoid errors like TopologyException: Input geom 1 is invalid: Self-intersection\n",
    "\n",
    "            #print(diff_poly.geom_type)\n",
    "            if diff_poly.geom_type == 'MultiPolygon':\n",
    "\n",
    "                areas = []\n",
    "                idx_sensor = []\n",
    "                for poly in diff_poly.geoms:\n",
    "                    areas.append(poly.area)\n",
    "                    #idx = 1 if poly.contains(sensor) else 0\n",
    "                    idx_sensor.append(poly.buffer(buffer_sensor).contains(sensor))\n",
    "                areas = np.array(areas)\n",
    "                idx_sensor = np.array(idx_sensor)\n",
    "\n",
    "                if np.where(idx_sensor)[0].size == 0: # Check for potential issues with clustering, i.e., sensor not in any of the shapes\n",
    "                    continue\n",
    "                    \n",
    "                if np.where(idx_sensor)[0].size > 1: # If multiple shapes contain the sensors (because of the buffer) we select the smallest shape\n",
    "                    idx_min = np.argmin(areas)\n",
    "                    for idx in range(len(idx_sensor)):\n",
    "                        if not idx == idx_min:\n",
    "                            idx_sensor[idx] = False\n",
    "\n",
    "                #scenario = 0\n",
    "                idx_other = -1\n",
    "                if len(areas) > 2:\n",
    "                    if areas[np.where(idx_sensor)[0][0]] < np.max(areas):\n",
    "                        #scenario = 1 # two small areas with one of them containing the sensor\n",
    "                        idx_other = np.where(~idx_sensor)[0]\n",
    "                        idx_other = idx_other[np.argmin(areas[idx_other])]\n",
    "\n",
    "                polygon1 = MultiPolygon()\n",
    "                cpt_area = -1\n",
    "                for poly in diff_poly.geoms:\n",
    "                    cpt_area += 1\n",
    "                    #print(f'{cpt_area}/{len(areas)}: {poly.area}')\n",
    "\n",
    "                    if idx_sensor[cpt_area] or (idx_other == cpt_area):\n",
    "                        #print(f'- Selected {cpt_area}')\n",
    "                        polygon1 = polygon1.union(poly)\n",
    "\n",
    "            else:\n",
    "                if not polygon1.contains(sensor):\n",
    "                    polygon1 = diff_poly\n",
    "\n",
    "            if (polygon1.area-last_area>1e11) or (iin == 0):\n",
    "                last_area = polygon1.area\n",
    "                polygon1_return = polygon1\n",
    "                diff_poly_return = diff_poly\n",
    "                \n",
    "            break\n",
    "\n",
    "    return polygon1_return, diff_poly_return\n",
    "\n",
    "def plot_TL_map(polygon_map, polygon1, polygon2, intersection, proj, lon_0_current, lat_0_current):\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(*polygon_map.exterior.xy, label='TL', color='tab:blue')\n",
    "    if polygon1.geom_type == 'MultiPolygon':\n",
    "        for poly in polygon1.geoms:\n",
    "            plt.plot(*poly.exterior.xy, label='TL', color='tab:blue', )\n",
    "    else:\n",
    "        plt.plot(*polygon1.exterior.xy, label='TL', color='tab:red', )\n",
    "    for poly in polygon2.geoms:\n",
    "        if poly.geom_type == 'LineString':\n",
    "            plt.plot(*poly.xy, label='venus', color='orange')\n",
    "        else:\n",
    "            plt.plot(*poly.exterior.xy, label='venus', color='orange')\n",
    "            for interior in poly.interiors:\n",
    "                plt.plot(*interior.xy, label='venus', color='orange')\n",
    "    if intersection.geom_type == 'MultiPolygon':\n",
    "        for poly in intersection.geoms:\n",
    "            if poly.geom_type == 'LineString':\n",
    "                plt.scatter(*poly.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "            else:\n",
    "                plt.scatter(*poly.exterior.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "                for interior in poly.interiors:\n",
    "                    plt.plot(*interior.xy, label='inter', color='black')\n",
    "    elif intersection.geom_type == 'Polygon':\n",
    "        plt.scatter(*intersection.exterior.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "        for interior in intersection.interiors:\n",
    "            plt.scatter(*interior.xy, label='inter', color='black', alpha=0.5, s=5)\n",
    "    x, y = proj(lon_0_current, lat_0_current)\n",
    "    plt.scatter(x, y, marker='^', edgecolor='black', color='red', s=200, zorder=1000)\n",
    "    plt.title(f'Surface area ratio: {intersection.area/polygon2.area:.2e}')\n",
    "\n",
    "def compute_surface_area_ratio(intersection, polygon_map):\n",
    "    return intersection.area/polygon_map.area\n",
    "\n",
    "def compute_region_intraplate(VENUS, polygon_map, proj):\n",
    "\n",
    "    if 'intraplate' in VENUS:\n",
    "        return VENUS['intraplate']\n",
    "\n",
    "    polygon2 = Polygon()\n",
    "    for region in VENUS:\n",
    "        polygon2 = polygon2.union( compute_region_venus(polygon_map, VENUS[region].exterior, proj, show_bar=False) )\n",
    "\n",
    "    return polygon_map.difference(polygon2)\n",
    "\n",
    "\n",
    "R0 = 6052000  # Venus' radius in meters\n",
    "g = pyproj.Geod(proj='robin', lat_0=0., lon_0=0., a=R0, b=R0)    \n",
    "l_radius = np.arange(10000, np.pi*R0/1.001, 500000)\n",
    "#lat_0 = 30.1478  # Latitude sensor\n",
    "#lon_0 = 138.1445  # Longitude sensor\n",
    "dlat = 20\n",
    "l_lon = np.arange(-179, 179, dlat*2)\n",
    "l_lat = np.arange(-85, 90, dlat)\n",
    "#l_lon = np.arange(-179, 180, 1)\n",
    "LONS, LATS = np.meshgrid(l_lon, l_lat)\n",
    "LONS, LATS = LONS.ravel(), LATS.ravel()\n",
    "l_points = list(zip(LONS, LATS))\n",
    "num_points = 2000\n",
    "buffer_line = 120000\n",
    "\n",
    "#LATS = np.array([40.01010101010101, 0., -30])\n",
    "#LONS = np.array([70.91919191919192, 0., -58])\n",
    "#l_points = list(zip(LONS, LATS))\n",
    "#LATS = LATS[[0, 189]]\n",
    "#LONS = LONS[[0, 189]]\n",
    "#l_points = list(zip(LONS, LATS))\n",
    "#l_radius = np.array([l_radius[37]])\n",
    "#l_radius = np.arange(10000, 0.2e7, 100000)\n",
    "#num_points = 500\n",
    "#buffer_line = 90000\n",
    "\n",
    "proj = pyproj.Proj(proj='robin', lat_0=l_points[0][1], lon_0=l_points[0][0], a=R0, b=R0)\n",
    "recompute_surface1 = True\n",
    "if recompute_surface1:\n",
    "    surface1_lon, surface1_lat, n_subshapes, surface1_lon_init, surface1_lat_init = spherical_cap_boundary_v3(g, proj, l_points[0][0], LATS, LONS, l_radius, num_points=num_points)\n",
    "polygon_map, _ = compute_whole_map_region(l_points[0][0], proj, dlon=1., dlat=1)\n",
    "VENUS['intraplate'] = compute_region_intraplate(VENUS, polygon_map, proj)\n",
    "\n",
    "ratio_df = pd.DataFrame()\n",
    "polygon1s = []\n",
    "if True:\n",
    "    for iregion, region in enumerate(VENUS):\n",
    "        \n",
    "        iloc = -1\n",
    "        print(f'- {region} -')\n",
    "        itotal = -1\n",
    "        iregion_lon0 = -1\n",
    "        \n",
    "        lon_0, _ = l_points[0]\n",
    "        polygon_map, _ = compute_whole_map_region(lon_0, proj, dlon=1., dlat=1)\n",
    "        print('- Finding region polygons')\n",
    "        if region == 'intraplate':\n",
    "            polygon2 = VENUS[region]\n",
    "        else:\n",
    "            polygon2 = compute_region_venus(polygon_map, VENUS[region].exterior, proj, show_bar=False)\n",
    "            \n",
    "        print('- Looping over all sensor locations')\n",
    "        for lon_0_current, lat_0_current in tqdm(l_points):\n",
    "\n",
    "            iloc += 1\n",
    "            \n",
    "            #surface1_loc = surface1[iloc*num_points*len(l_radius):(iloc+1)*num_points*len(l_radius), :]\n",
    "            \n",
    "            sensor = Point(proj(lon_0_current, lat_0_current))\n",
    "\n",
    "            last_area = 0\n",
    "            base_n_components = 1\n",
    "            comps = []\n",
    "            iregion_lon0 += 1\n",
    "            for iradius, radius in enumerate(l_radius):\n",
    "\n",
    "                itotal += 1\n",
    "                #if (iradius < 30) | (iloc < 188):\n",
    "                #    continue\n",
    "                \n",
    "                #print(f'| iloc: {iloc} iradius: {iradius}')\n",
    "                #if iregion == 0:\n",
    "                #    continue\n",
    "                \n",
    "                if iregion == 0:\n",
    "                    trajectory = np.c_[surface1_lon[:,iloc,iradius], surface1_lat[:,iloc,iradius]]\n",
    "                    #poly, diff_poly = compute_TL_region_v2(polygon_map, surface1_loc[iradius*num_points:(iradius+1)*num_points, :], proj, lon_0, lon_0_current, sensor, n_subshapes[itotal], subsample_db=5, buffer_line=buffer_line)\n",
    "                    poly, diff_poly = compute_TL_region_v2(polygon_map, trajectory, proj, lon_0, lon_0_current, sensor, n_subshapes[itotal], subsample_db=5, buffer_line=buffer_line)\n",
    "                    polygon1s.append( poly )\n",
    "                    intersection = polygon2.intersection(polygon1s[-1])\n",
    "                else:\n",
    "                    intersection = polygon2.intersection(polygon1s[itotal])\n",
    "                \n",
    "                ratio = compute_surface_area_ratio(intersection, polygon_map)\n",
    "                ratio_map = compute_surface_area_ratio(intersection, polygon2)\n",
    "                loc_dict = {'region': region, 'iloc': iloc, 'lon': lon_0_current, 'lat': lat_0_current, 'iradius': iradius, 'radius': radius, 'ratio': ratio, 'ratio_map': ratio_map}\n",
    "                ratio_df = ratio_df.append([loc_dict])\n",
    "                \n",
    "                #plot_TL_map(polygon_map, polygon1s[itotal], polygon2, intersection, proj, lon_0_current, lat_0_current)\n",
    "        \n",
    "        \n",
    "    #ratio_df.to_csv('./test_data_Venus/surface_ratios.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-confirmation",
   "metadata": {},
   "source": [
    "## Save surface ratios to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df.to_csv('./test_data_Venus/surface_ratios_fixed.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-handbook",
   "metadata": {},
   "source": [
    "## Visualize surface ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TL_region_v2(polygon_map, coords_poly1, proj, lon_0, lon_0_current, sensor, n_subshape, subsample_db=1, buffer_line=300000, buffer_sensor=180000, n_init_max=10, threshold_neighbor_pts = 5e5):\n",
    "    \n",
    "    proj_sensor = proj(lon_0_current, 0.)\n",
    "    proj_sensor_ref = proj(lon_0, 0.)\n",
    "    offset = abs(proj_sensor_ref[0]-proj_sensor[0])\n",
    "\n",
    "    #coords_poly1 = np.roll(coords_poly1, -np.argmax(abs(coords_poly1[:,0]-offset))-1, axis=0)\n",
    "    last_area = 0\n",
    "    plt.figure()\n",
    "    plt.title(n_subshape)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    coords_poly1_fixed = scaler.fit_transform(coords_poly1)\n",
    "    #plt.scatter(coords_poly1_fixed[1:-2,0], coords_poly1_fixed[1:-2,1], c=np.arange(coords_poly1_fixed[1:-2,1].size))\n",
    "    \n",
    "    for iin, n_components in enumerate([n_subshape]):\n",
    "        \n",
    "        l_n_init = np.arange(1,n_init_max)\n",
    "        l_covariances = ['full', 'spherical']\n",
    "        NINIT, COV = np.meshgrid(l_n_init, l_covariances)\n",
    "        NINIT, COV = NINIT.ravel(), COV.ravel()\n",
    "        for n_init, cov in zip(NINIT, COV):\n",
    "        \n",
    "            print(f'---> n_comp: {n_components} n_init: {n_init} cov: {cov}')\n",
    "        \n",
    "            clustering = GaussianMixture(n_components=n_components, n_init=n_init, covariance_type=cov).fit_predict(coords_poly1_fixed)\n",
    "            polygon1 = Polygon()\n",
    "            max_dx = 0.\n",
    "            for label in np.unique(clustering):\n",
    "                max_dx = max(max_dx, abs(np.diff(coords_poly1[clustering==label][:-1,0])).max())\n",
    "                plt.plot(coords_poly1[clustering==label][:,0], coords_poly1[clustering==label][:,1])\n",
    "                polygon1 = polygon1.union( LineString(coords_poly1[clustering==label][:]).buffer(buffer_line) )\n",
    "            \n",
    "            if max_dx > threshold_neighbor_pts: # Check for potential issues with clustering, i.e., shared points between shapes\n",
    "                continue\n",
    "            \n",
    "            diff_poly = polygon_map.difference(polygon1.buffer(10)) # The buffer here is to avoid errors like TopologyException: Input geom 1 is invalid: Self-intersection\n",
    "\n",
    "            #print(diff_poly.geom_type)\n",
    "            if diff_poly.geom_type == 'MultiPolygon':\n",
    "\n",
    "                areas = []\n",
    "                idx_sensor = []\n",
    "                for poly in diff_poly.geoms:\n",
    "                    areas.append(poly.area)\n",
    "                    #idx = 1 if poly.contains(sensor) else 0\n",
    "                    idx_sensor.append(poly.buffer(buffer_sensor).contains(sensor))\n",
    "                areas = np.array(areas)\n",
    "                idx_sensor = np.array(idx_sensor)\n",
    "\n",
    "                if np.where(idx_sensor)[0].size == 0: # Check for potential issues with clustering, i.e., sensor not in any of the shapes\n",
    "                    continue\n",
    "                    \n",
    "                if np.where(idx_sensor)[0].size > 1: # If multiple shapes contain the sensors (because of the buffer) we select the smallest shape\n",
    "                    idx_min = np.argmin(areas)\n",
    "                    for idx in range(len(idx_sensor)):\n",
    "                        if not idx == idx_min:\n",
    "                            idx_sensor[idx] = False\n",
    "\n",
    "                #scenario = 0\n",
    "                idx_other = -1\n",
    "                if len(areas) > 2:\n",
    "                    if areas[np.where(idx_sensor)[0][0]] < np.max(areas):\n",
    "                        #scenario = 1 # two small areas with one of them containing the sensor\n",
    "                        idx_other = np.where(~idx_sensor)[0]\n",
    "                        idx_other = idx_other[np.argmin(areas[idx_other])]\n",
    "\n",
    "                polygon1 = MultiPolygon()\n",
    "                cpt_area = -1\n",
    "                for poly in diff_poly.geoms:\n",
    "                    cpt_area += 1\n",
    "                    #print(f'{cpt_area}/{len(areas)}: {poly.area}')\n",
    "\n",
    "                    if idx_sensor[cpt_area] or (idx_other == cpt_area):\n",
    "                        #print(f'- Selected {cpt_area}')\n",
    "                        polygon1 = polygon1.union(poly)\n",
    "\n",
    "            else:\n",
    "                if not polygon1.contains(sensor):\n",
    "                    polygon1 = diff_poly\n",
    "\n",
    "            if (polygon1.area-last_area>1e11) or (iin == 0):\n",
    "                last_area = polygon1.area\n",
    "                polygon1_return = polygon1\n",
    "                diff_poly_return = diff_poly\n",
    "                \n",
    "            break\n",
    "\n",
    "    return polygon1_return, diff_poly_return\n",
    "\n",
    "def plot_TL_map(polygon_map, polygon1, polygon2, intersection, proj, lon_0_current, lat_0_current):\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(*polygon_map.exterior.xy, label='TL', color='tab:blue')\n",
    "    if polygon1.geom_type == 'MultiPolygon':\n",
    "        for poly in polygon1.geoms:\n",
    "            plt.plot(*poly.exterior.xy, label='TL', color='tab:blue', )\n",
    "    else:\n",
    "        plt.plot(*polygon1.exterior.xy, label='TL', color='tab:red', )\n",
    "    for poly in polygon2.geoms:\n",
    "        if poly.geom_type == 'LineString':\n",
    "            plt.plot(*poly.xy, label='venus', color='orange')\n",
    "        else:\n",
    "            plt.plot(*poly.exterior.xy, label='venus', color='orange')\n",
    "            for interior in poly.interiors:\n",
    "                plt.plot(*interior.xy, label='venus', color='orange')\n",
    "    if intersection.geom_type == 'MultiPolygon':\n",
    "        for poly in intersection.geoms:\n",
    "            if poly.geom_type == 'LineString':\n",
    "                plt.scatter(*poly.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "            else:\n",
    "                plt.scatter(*poly.exterior.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "                for interior in poly.interiors:\n",
    "                    plt.plot(*interior.xy, label='inter', color='black')\n",
    "    elif intersection.geom_type == 'Polygon':\n",
    "        plt.scatter(*intersection.exterior.xy, label='inter', color='black', alpha=0.5, s=5, )\n",
    "        for interior in intersection.interiors:\n",
    "            plt.scatter(*interior.xy, label='inter', color='black', alpha=0.5, s=5)\n",
    "    x, y = proj(lon_0_current, lat_0_current)\n",
    "    plt.scatter(x, y, marker='^', edgecolor='black', color='red', s=200, zorder=1000)\n",
    "    plt.title(f'Surface area ratio: {intersection.area/polygon2.area:.5e}')\n",
    "\n",
    "buffer_line = 120000\n",
    "#iloc = 46\n",
    "#iradius = len(l_radius)-16\n",
    "#iradius -= 1\n",
    "print(iradius, iloc)\n",
    "itotal = iloc*len(l_radius) + iradius\n",
    "print('l_radius:', l_radius[iradius])\n",
    "trajectory = np.c_[surface1_lon[:,iloc,iradius], surface1_lat[:,iloc,iradius]]\n",
    "sensor = Point(proj(l_points[iloc][0], l_points[iloc][1]))\n",
    "poly, diff_poly = compute_TL_region_v2(polygon_map, trajectory, proj, lon_0, l_points[iloc][0], sensor, 1, subsample_db=5, buffer_line=buffer_line)\n",
    "intersection = polygon2.intersection(poly)\n",
    "plot_TL_map(polygon_map, poly, polygon2, intersection, proj, l_points[iloc][0], l_points[iloc][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
